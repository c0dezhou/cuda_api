# 单卡单核 / 单卡多核 / 多卡多核
* 单进程多线程
  /*
    一个场景是使用多个线程来执行不同的CUDA操作，例如对不同的设备或模块进行操作，然后使用相同的CUDA context来管理不同线程之间的设备资源和状态12。这个场景可以测试cudadriver api的线程安全性和context共享性。

    另一个场景是使用多个线程来执行相同的CUDA操作，例如对相同的设备或模块进行操作，然后使用不同的CUDA stream来管理不同线程之间的操作顺序和并发性12。这个场景可以测试cudadriver api的stream机制和并行能力。

    还有一个场景是使用多个线程来执行交错的CUDA操作，例如对相同的设备或模块进行不同的操作，然后使用不同的CUDA event来管理不同线程之间的操作同步和依赖性12。这个场景可以测试cudadriver api的event机制和协作能力。
  */

* 多进程单线程
  /*
    尝试帮助您设计一些 cuda driver api 的多进程单线程场景，但我不能保证它们的正确性或性能。，cuda driver api 是一个与语言无关的二进制兼容的接口，用于在 GPU 上执行 cuda 应用程序。如果您想在多个进程中使用 cuda driver api，您需要考虑以下几个方面：

- 每个进程都需要创建和销毁自己的 cuda 上下文，这是一个虚拟的执行空间，包含了代码和数据。每个 GPU 同时只能有一个活跃的上下文，所以多个进程可能会互相阻塞或串行化。
- 如果您想利用 GPU 的 Hyper-Q 功能，即在同一个 GPU 上并发执行多个内核，您可以使用 Multi-Process Service (MPS) 来共享一个上下文。MPS 是一个替代的 cuda driver api 实现，它可以透明地使多个进程协作运行 cuda 应用程序。MPS 在 Volta 架构及以后的 GPU 上提供了一些改进，例如直接提交工作、独立的地址空间和有限的资源配置。
- 如果您想在同一个进程中使用多个线程来调用 cuda driver api，您需要注意线程安全和上下文迁移的问题。cuda driver api 本身是线程安全的，但是一些函数可能会影响全局状态，例如设置当前设备或当前上下文。您可以使用 cuCtxSetCurrent 和 cuCtxGetCurrent 函数来在不同的线程中切换上下文。

基于以上信息，我为您生成了一些可能的场景：

- 场景一：您有一个单进程单线程的 cuda 应用程序，它在一个 GPU 上执行一系列的内核。您想将这个应用程序扩展到多个 GPU 上，以提高计算能力。您可以使用 cuda driver api 的 cuDeviceGetCount 和 cuDeviceGet 函数来获取可用的 GPU 数量和句柄，然后为每个 GPU 创建一个子进程，并在子进程中创建和销毁自己的 cuda 上下文。您需要在主进程和子进程之间建立一种通信机制，例如管道或共享内存，来传递数据和指令。
- 场景二：您有一个单进程多线程的 cuda 应用程序，它在一个 GPU 上执行一系列的内核。每个线程负责一个不同的任务，例如数据预处理、计算或可视化。您想让这些线程并发地使用 cuda driver api 来加速他们的任务。您可以使用 cuda driver api 的 cuCtxCreate 和 cuCtxDestroy 函数来为每个线程创建和销毁自己的 cuda 上下文，并使用 cuCtxSetCurrent 和 cuCtxGetCurrent 函数来在不同的线程中切换上下文。您需要注意同步和错误处理的问题，以避免冲突和死锁。
- 场景三：您有一个多进程单线程的 cuda 应用程序，它在一个 GPU 上执行一系列的内核。每个进程负责一个不同的任务，例如数据预处理、计算或可视化。您想让这些进程协作地使用 cuda driver api 来加速他们的任务，并利用 GPU 的 Hyper-Q 功能来并发执行多个内核。您可以使用 MPS 来共享一个 cuda 上下文，并使用 MPS 控制工具来启动和停止 MPS 服务器、设置环境变量和监控状态。您需要注意 MPS 的限制和要求，例如不支持 OpenGL 或 Direct3D 互操作、不支持 UVA 或 IPC 等。

希望这些场景对您有所帮助。如果您有其他问题，请随时提出。

(1) Multi-Process Service :: GPU Deployment and Management Documentation. https://docs.nvidia.com/deploy/mps/index.html.
(2) Multiple processes launching CUDA kernels in parallel. https://stackoverflow.com/questions/14895034/multiple-processes-launching-cuda-kernels-in-parallel.
(3) CUDA Driver API :: CUDA Toolkit Documentation. https://docs.nvidia.com/cuda/cuda-driver-api/index.html.
(4) 附录D - CUDA 的动态并行 - NVIDIA 技术博客. https://developer.nvidia.com/zh-cn/blog/cuda-dynamic-parallelism-cn/.
(5) 浅谈Cuda driver API - 知乎. https://zhuanlan.zhihu.com/p/111602648.
  */
* 多进程多线程
  * 假设您有一个 cuda 应用程序，它需要在一个 GPU 上执行四个不同的任务，每个任务都需要多个内核
  * 单个 GPU 上可以有多进程多线程的场景，但是需要使用 MPS 来共享一个 cuda 上下文，并在每个进程中使用 cuCtxSetCurrent 和 cuCtxGetCurrent 函数来在不同的线程中切换上下文。这样可以让多个进程和多个线程并发地使用 cuda driver api 来加速他们的任务，并利用 GPU 的 Hyper-Q 功能来并发执行多个内核。但是您也需要注意 MPS 的限制和要求，例如不支持 OpenGL 或 Direct3D 互操作、不支持 UVA 或 IPC 等。

* 多线程共享stream
  /*
    一个测试场景是使用多个线程来执行不同的任务，例如读取文件、处理数据、显示结果等，然后使用一个共享的stream来执行与GPU相关的操作，例如内存拷贝、内核调用等，然后比较它们的执行时间和性能。这个场景可以测试多线程共享stream的互斥和竞争条件。

    另一个测试场景是使用多个线程来执行相同的任务，例如对同一份数据进行不同的处理或分析，然后使用一个共享的stream来执行与GPU相关的操作，例如内存拷贝、内核调用等，然后比较它们的执行时间和性能。这个场景可以测试多线程共享stream的并行和协作能力。

    还有一个测试场景是使用多个线程来执行相互依赖的任务，例如一个线程的输出是另一个线程的输入，或者一个线程需要等待另一个线程完成后才能开始，然后使用一个共享的stream来执行与GPU相关的操作，例如内存拷贝、内核调用等，然后比较它们的执行时间和性能。这个场景可以测试多线程共享stream的同步和通信机制。
  */
* 多stream(>16)
    /**
    一个测试场景是使用多个stream来执行不同类型的内核，例如矩阵乘法、矩阵转置、向量加法等，然后比较它们的执行时间和性能。这个场景可以测试不同类型的内核在多个stream上的并发能力和资源利用率。
    
    另一个测试场景是使用多个stream来执行相同类型的内核，但是每个内核处理不同大小或不同形状的数据，例如矩阵、图像、视频等，然后比较它们的执行时间和性能。这个场景可以测试相同类型的内核在多个stream上的负载均衡和数据传输效率。
    
    还有一个测试场景是使用多个stream来执行相互依赖的内核，例如一个内核的输出是另一个内核的输入，或者一个内核需要等待另一个内核完成后才能开始，然后比较它们的执行时间和性能。这个场景可以测试多个stream上的内核同步和协调机制。
    */
* 多stream之间的同步
  /*
    一个复杂同步场景是使用多个stream来执行不同阶段的任务，例如预处理、计算、后处理等，然后使用事件或信号量来控制不同stream之间的依赖关系，例如一个stream需要等待另一个stream完成某个事件或信号量后才能开始，或者一个stream需要通知另一个stream某个事件或信号量已经完成，然后比较它们的执行时间和性能。这个场景可以测试多stream之间的事件或信号量同步机制。
    
    另一个复杂同步场景是使用多个stream来执行相同阶段的任务，例如对不同数据集进行相同的计算或分析，然后使用屏障或栅栏来控制不同stream之间的并行关系，例如一个stream需要等待所有其他stream都到达某个屏障或栅栏后才能继续，或者一个stream需要通知所有其他stream都到达某个屏障或栅栏后才能继续，然后比较它们的执行时间和性能。这个场景可以测试多stream之间的屏障或栅栏同步机制。
    
    还有一个复杂同步场景是使用多个stream来执行交错的任务，例如对相同数据集进行不同的处理或分析，然后使用原子操作或临界区来控制不同stream之间的竞争关系，例如一个stream需要对某个共享变量进行原子操作或进入临界区后才能修改它，或者一个stream需要检查某个共享变量是否被其他stream修改过，然后比较它们的执行时间和性能。这个场景可以测试多stream之间的原子操作或临界区同步机制。


    一个简单的同步场景是使用两个stream来执行不同的任务，例如一个stream负责数据的输入和输出，另一个stream负责数据的处理和分析，然后使用cuStreamSynchronize()函数来让主机等待两个stream都完成后再继续执行。这个场景可以测试两个stream之间的主机同步机制。
    
    另一个简单的同步场景是使用两个stream来执行相同的任务，例如对同一份数据进行不同的处理或分析，然后使用cuStreamWaitEvent()函数和cuEventRecord()函数来让一个stream等待另一个stream发出一个事件后再继续执行。这个场景可以测试两个stream之间的事件同步机制。
    
    还有一个简单的同步场景是使用两个stream来执行交错的任务，例如对相同数据集进行不同的处理或分析，然后使用cuMemcpyAsync()函数和cuMemcpyDtoDAsync()函数来在两个stream之间异步地拷贝数据。这个场景可以测试两个stream之间的内存拷贝同步机制。

    如果您的stream数量大于16，您可以使用类似的方法来设计多stream同步场景，但是您可能需要考虑一些额外的因素，例如：

    您的GPU设备支持的最大stream数量和并发能力。不同的GPU设备可能有不同的限制和特性，您可以使用cuDeviceGetAttribute()函数来查询您的GPU设备的属性，例如CU_DEVICE_ATTRIBUTE_MAX_STREAMS、CU_DEVICE_ATTRIBUTE_CONCURRENT_KERNELS等。
    
    您的stream之间的依赖关系和执行顺序。不同的stream之间可能有不同的依赖关系和执行顺序，您可以使用不同的同步机制来控制它们，例如事件、信号量、屏障、原子操作等。您也可以使用CUDA图来表示和优化您的stream之间的依赖关系和执行顺序。
    
    您的stream之间的资源竞争和负载均衡。不同的stream之间可能有不同的资源竞争和负载均衡，您可以使用不同的策略来管理它们，例如动态分配、优先级调整、资源共享等。您也可以使用CUDA分析工具来监测和优化您的stream之间的资源竞争和负载均衡。

    一个例子是使用多个stream来实现矩阵乘法的分块算法1，其中每个stream负责一个子矩阵的计算，并且使用事件来同步不同stream之间的数据传输和内核执行。
  */


* null stream和non blocking stream
* 单stream 多 event 同步
  /* 
    设计一个单stream多event同步的场景，但请注意，这个场景可能不是最优的或最实用的，只是一个可能的想法。在这个context中，一个人可能会说：

    一个单stream多event同步的场景是使用一个stream来执行多个任务，例如对多个数据集进行相同或不同的处理或分析，然后使用cuEventRecord()函数和cuEventSynchronize()函数来在每个任务之间插入一个事件，并且让主机等待每个事件完成后再继续执行。这个场景可以测试单stream中的事件同步机制。

    另一个单stream多event同步的场景是使用一个stream来执行多个任务，例如对多个图像进行相同或不同的处理或分析，然后使用cuEventRecord()函数和cuStreamWaitEvent()函数来在每个任务之间插入一个事件，并且让另一个stream等待每个事件完成后再继续执行。这个场景可以测试不同stream之间的事件同步机制。
    
    还有一个单stream多event同步的场景是使用一个stream来执行多个任务，例如对多个视频进行相同或不同的处理或分析，然后使用cuEventRecord()函数和cuEventQuery()函数来在每个任务之间插入一个事件，并且让主机轮询每个事件是否完成，然后根据结果做出相应的动作。这个场景可以测试主机和设备之间的事件同步机制。


以下是一些可能的单流多事件同步或异步场景：

- 场景一：使用单个流来实现数据的分段处理。例如，假设您有一个很大的数据集，您想要在设备上执行一个核函数。您可以将数据集分成若干个段，每个段对应一个核函数调用。然后，您可以在单个流中依次执行这些核函数调用，并在每个调用之后插入一个事件。这样，您可以利用事件来记录每个段的处理状态，并在需要时使用cuEventQuery或cuEventSynchronize等函数来查询或等待某个段的完成情况。

- 场景二：使用单个流来实现不同类型的操作的顺序执行。例如，假设您有一个复杂的算法，它包含多个不同类型的操作，例如内存拷贝、核函数执行、主机函数调用等。您可以将这些操作按照逻辑顺序放在单个流中，并在每个操作之后插入一个事件。然后，您可以使用cuStreamWaitEvent让主机函数等待某个事件完成，从而实现一定的同步逻辑。这样，您可以利用事件来控制不同类型的操作的执行顺序，并在需要时进行主机和设备之间的通信。

- 场景三：使用单个流来实现多设备之间的协作。例如，假设您有两个或多个设备，您想要在它们之间传输和处理数据。您可以为每个设备创建一个单独的流，并使用cuMemcpyPeerAsync等函数来实现设备之间的异步内存拷贝。然后，您可以在每个设备上执行相应的核函数，并在每个内存拷贝或核函数调用之后插入一个事件。然后，您可以使用cuEventRecord和cuEventSynchronize等函数来实现设备之间的同步逻辑。这样，您可以利用事件来控制不同设备之间的数据交换和计算，并在需要时进行同步。
*/


* 多stream 多 event 同步
    /*

以下是一些可能的多流多事件同步场景：

- 场景一：使用多个流来实现数据的分块传输和处理。例如，假设您有一个很大的数据集，您想要将其从主机内存拷贝到设备内存，并在设备上执行一个核函数。您可以将数据集分成若干个块，每个块对应一个流。然后，您可以在每个流中依次执行异步的内存拷贝和核函数调用。这样，您可以利用流之间的并行性，让不同的数据块在不同的时间段进行传输和处理，从而提高效率。为了保证数据的正确性，您可以在每个流中插入一个事件，并在所有的流完成后使用cuEventSynchronize或cuStreamWaitEvent等待所有的事件完成。

- 场景二：使用多个流来实现不同类型的操作的并行执行。例如，假设您有两个不同类型的核函数，一个是计算密集型的，一个是内存密集型的。您可以将这两种类型的核函数分别放在不同的流中，并在每个流中插入一个事件。然后，您可以使用cuStreamWaitEvent让一个流等待另一个流中的事件完成，从而实现一定的同步逻辑。这样，您可以利用流之间的并行性，让不同类型的操作在不同的硬件资源上执行，从而提高效率。

- 场景三：使用多个流来实现多设备之间的协作。例如，假设您有两个或多个设备，您想要在它们之间传输和处理数据。您可以为每个设备创建一个或多个流，并使用cuMemcpyPeerAsync等函数来实现设备之间的异步内存拷贝。然后，您可以在每个设备上执行相应的核函数，并使用cuEventRecord和cuEventSynchronize等函数来实现设备之间的同步逻辑。这样，您可以利用流之间的并行性，让不同设备之间进行数据交换和计算，从而提高效率。
    */

# 多机多卡
同上

# 显存分配释放压测， 碎片 
2M 10M 2M*N 的多次交叉分配和释放

# stream性能
多stream性能相对于单stream的不增加调度开销（stream队列没有任务）

# 稳定性测试 2机16卡收敛验证（72h）